{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222e602a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Quiz [20 minutes]\n",
    "\n",
    "1. List the assumptions implied by the ***linear regression model*** specification\n",
    "\n",
    "   $$y_i \\sim \\mathcal N(\\mathbf{x}_i^\\top \\boldsymbol \\beta,\\sigma^2), i=1,\\cdots,n$$\n",
    "\n",
    "2. Rewrite the above expression as a single sample from a ***multivariate normal distribution*** using the ***multivariate random variable*** $\\mathbf{y}_{n\\times 1}$, ***design matrix*** $X_{n\\times p}$, and ***parameters*** $\\boldsymbol \\beta_{p \\times 1}$ and $\\boldsymbol \\Sigma_{n \\times n} = \\sigma^2 I_{n \\times n}$ (and include all the dimensions in your expression)\n",
    "\n",
    "3. Write down the mathematical expression of the pdf of the above ***linear regression model*** as a ***multivariate normal distribution*** in terms of $\\boldsymbol \\Sigma_{n \\times n}$ (instead of $\\sigma^2 I_{n \\times n}$) (and feel free to look up the expression of the pdf online if you need to)\n",
    "\n",
    "4. What family of ***priors*** would be ***conjugate*** for the ***multivariate parameter*** $\\boldsymbol \\beta$ for this ***linear regression model***?\n",
    "\n",
    "5. What mathmematical form would a ***conjugate prior*** for the ***covariance matrix*** $\\boldsymbol \\Sigma$ (as opposed to $\\sigma^2$ as in $\\sigma^2I$) be proporitional to  for this ***linear regression model***? \n",
    "\n",
    "   Hint: \n",
    "\n",
    "   $$(\\mathbf {y} -\\mathbf{X \\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol \\beta}) = \\textrm{tr}\\left((\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol \\beta}) \\right) = \\textrm{tr}\\left((\\mathbf {y} - \\mathbf{X\\boldsymbol \\beta})(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1} \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a4e3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Solutions [10 minutes]\n",
    "\n",
    "1. Assumptions of ***Linear Regression***\n",
    "    1. indepedendent\n",
    "    2. homoskedastic \n",
    "    3. normally distributed residuals\n",
    "    4. linear form and $\\mathbf{x_i}$ having no randomness (measured without error)\n",
    "\n",
    "2. ***Multivariate Normal Distribution*** specification of muliple linear regression\n",
    "\n",
    "   $$\\mathbf{y}_{n\\times 1} \\sim \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})$$\n",
    "\n",
    "3. For ***positive definite*** $\\Sigma$\n",
    "\n",
    "   $$p(\\textbf{y}_{n\\times 1}) = (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right) $$\n",
    "\n",
    "4. The ***conjugate prior*** for $\\boldsymbol \\beta$ would be $\\boldsymbol \\beta \\sim \\mathcal{MVN}(\\boldsymbol \\beta_0, \\boldsymbol\\Sigma_\\beta)$ \n",
    "\n",
    "5. The ***conjugate prior*** for $\\boldsymbol \\Sigma$ would be $p(\\boldsymbol \\Sigma) \\propto \\det({\\boldsymbol {\\Sigma }})^{-v/2} \\exp \\left(-{\\frac {1}{2}}\\textrm{tr}\\left(\\Psi{\\boldsymbol {\\Sigma }}^{-1} \\right)\\right)$ \n",
    "\n",
    "   an [Inverse-Wishart distribution](https://en.wikipedia.org/wiki/Inverse-Wishart_distribution) and it is ***conjugate*** since [determinants multiply](https://proofwiki.org/wiki/Determinant_of_Matrix_Product) and [traces add](https://proofwiki.org/wiki/Trace_of_Sum_of_Matrices_is_Sum_of_Traces#:~:text=let%20A%2BB%20denote%20the,denotes%20the%20trace%20of%20A.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f761f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Linear Regression:<br>Multivariate Normal Distributions [10 minutes]\n",
    "\n",
    "\n",
    "\\begin{align*}\\require{cancel}\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}\\cancel{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}{\\frac{1}{\\sigma^{\\frac{n}{2}}}}\\exp \\left(-{\\frac {1}{2\\sigma^2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top\\cancel{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\n",
    "\\boldsymbol\\beta \\sim {} & \\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta) \\quad or\\;?\\\\\\\\\n",
    "\\sigma \\sim {} & exponential(\\lambda)  \\quad p(\\sigma) =  \\lambda e^{-\\lambda \\sigma}1_{[0,\\infty]}(\\sigma)\\\\\\\\\n",
    "\\end{align*}\n",
    "$$or \\quad \\sigma \\sim \\text{HalfNormal}(\\mu_\\sigma,\\sigma_\\sigma), \\sigma \\sim  \\text{InverseGamma}(\\alpha,\\beta), \\sigma \\sim \\text{TruncatedNormal}(\\mu_\\sigma,\\sigma_\\sigma,a,b) \\quad or \\; ?$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0790533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm; import numpy as np; n,p=100,10; X,y=np.zeros((n,p)),np.ones((n,1))\n",
    "with pm.Model() as MLR:\n",
    "    betas = pm.MvNormal('betas', mu=np.zeros((p,1)), cov=np.eye(p), shape=(p,1))\n",
    "    sigma = pm.TruncatedNormal('sigma', mu=1, sigma=1, lower=0) # it's just a half normal, actually\n",
    "    y = pm.Normal('y', mu=pm.math.dot(X, betas), sigma=sigma, observed=y)\n",
    "    # y = pm.MvNormal('y', mu=pm.math.dot(X, betas), cov=sigma**2*np.eye(n), shape=(n,1), observed=y)\n",
    "    \n",
    "with MLR:\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389faa1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 5: Part I\n",
    "\n",
    "1. Go get data from kaggle.com and do a ***Bayesian Linear Regression*** analysis\n",
    "\n",
    "```python\n",
    "import pymc as pm; import numpy as np\n",
    "n,p=100,10; X,y=np.zeros((n,p)),np.ones((n,1))\n",
    "# Replace this made up data with your data set from kaggle...\n",
    "with pm.Model() as MLR:\n",
    "    betas = pm.MvNormal('betas', mu=np.zeros((p,1)), cov=np.eye(p), shape=(p,1))\n",
    "    sigma = pm.TruncatedNormal('sigma', mu=1, sigma=1, lower=0) # half normal\n",
    "    y = pm.Normal('y', mu=pm.math.dot(X, betas), sigma=sigma, observed=y)\n",
    "\n",
    "with MLR:\n",
    "    idata = pm.sample()\n",
    "```    \n",
    "\n",
    "2. Choose ***prior*** that are sensible: certainly you might change the ***hyperparameters***, and perhaps you can experiment with different distributional families for `sigma`...\n",
    "\n",
    "3. [Optional] Assess the performance of the MCMC and note any issues or warnings\n",
    "\n",
    "    1. Traceplots, inference (credible) intervals, effective sample sizes, energy plots, warnings and other notes... just the usual stuff they do [here](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_overview.html#pymc-overview)\n",
    "\n",
    "4. [Optional] Perform ***Multiple Linear Regression*** diagnostics... residual plots, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5afef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Linear Regression?<br>Geneal $\\boldsymbol \\Sigma$ Instead of $\\sigma^2I$ [10 minutes]\n",
    "\n",
    "\\begin{align*}\\require{cancel}\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}\\cancel{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}{\\frac{1}{\\sigma^{\\frac{n}{2}}}}\\exp \\left(-{\\frac {1}{2\\sigma^2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top\\cancel{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\hline\\\\\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} \\cancel{= \\sigma^2I_{n\\times n}})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\n",
    "\\boldsymbol\\beta \\sim {} & \\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta) \\quad or\\;?\\\\\\\\\n",
    "p(\\boldsymbol \\Sigma) \\propto {} & \\det({\\boldsymbol {\\Sigma }})^{-v/2} \\exp \\left(-{\\frac {1}{2}}\\textrm{tr}\\left(\\Psi{\\boldsymbol {\\Sigma }}^{-1} \\right)\\right) \\quad or\\;?\n",
    "\\end{align*}\n",
    "\n",
    "**Do we forsee any problems with what we're going to do here?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96587f97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conjugate Multivariate Normal Priors [15 minutes]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\boldsymbol \\Sigma, \\mathbf{X})= {}& (2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "\\propto{}& \\exp\\left(\\mathbf{\\beta}^\\top\\mathbf{X}^\\top\\boldsymbol\\Sigma^{-1}\\mathbf{y} - \\frac{1}{2}\\mathbf{\\beta}^\\top \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X\\beta} \\right)\\\\\n",
    "\\propto{}& \\exp\\left( - \\frac{1}{2} \\left((\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} -\\beta\\right)^{\\!\\top} \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]\\left((\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} -\\beta\\right)  \\right)\\\\\n",
    "p(\\boldsymbol \\beta) \\propto 1 \\Longrightarrow {}& p(\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = \\mathcal{MVN}\\left(E[\\boldsymbol \\beta] = (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}, \\text{Var}[\\boldsymbol \\beta] = \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]^{-1} \\right)\\\\\n",
    "or \\quad {}& \\text{to use a conjugate family of priors...}\\\\\n",
    "p(\\boldsymbol \\beta) = {}& \\mathcal{MVN}\\left(E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\boldsymbol \\beta_0, \\text{Var}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\boldsymbol \\Sigma_\\beta \\right) \\quad \\text{ so}\\\\\n",
    "p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = {}& \\mathcal{MVN}\\left(E[\\boldsymbol \\beta] = \\text{Var}[\\boldsymbol \\beta]\\bigg( \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} + \\boldsymbol \\Sigma_\\beta^{-1}\\boldsymbol\\beta_0 \\right), \\text{Var}[\\boldsymbol \\beta] = \\left[\\mathbf{X}^{\\top}\\boldsymbol \\Sigma^{-1} \\mathbf{X} \\right]^{-1} + \\boldsymbol \\Sigma_\\beta^{-1} \\bigg)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Look familiar?}&\\, \\Downarrow{} \\quad\\quad\\quad \\underbrace{\\;\\,\\textbf{mean}\\,\\;}\\quad\\;\\underbrace{\\textbf{precision}}\\\\\n",
    "p(\\theta|x,\\theta_0,\\tau, \\phi) &={} \\text{N}\\left(\\frac{\\left(\\tau \\theta_0+\\phi\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau+n\\phi)}, \\tau+n\\phi \\right)\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d8081",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 5: Part II\n",
    "    \n",
    "## Answer the following with respect to $p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})$ on the previous slide\n",
    "    \n",
    "1. Rewrite $p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})$ in terms of $\\sigma^2$ (no longer using $\\Sigma$) if $\\Sigma=\\sigma^2I$\n",
    "\n",
    "2. What is $E[\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]$?\n",
    "\n",
    "3. What ***hyperparameters*** values (legal or illegal) would make $E[\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = (X^\\top X)^{-1} X^\\top y$?\n",
    "\n",
    "4. What ***hyperparameters*** values (legal or illegal) would make $E[  \\mathbf{\\hat y} = \\mathbf{X}\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = X(X^\\top X)^{-1} X^\\top y$?\n",
    "\n",
    "5. What is $\\text{Var}[\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97b1f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse-Wishart Conjugate Priors for $\\Sigma$ [15 minutes]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\Sigma, \\mathbf{X}) = {}& (2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "= {}& (2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}} \\textrm{tr}\\big((\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\big)\\right)\\\\\n",
    "= {}& (2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}} \\textrm{tr}\\big((\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}\\big)\\right)\\\\\n",
    "p(\\boldsymbol \\Sigma) \\propto 1 \\Longrightarrow {}& \n",
    "\\boldsymbol \\Sigma | \\boldsymbol \\beta, \\mathbf{X},\\mathbf{y} \\sim \\mathcal{W}^{-1}\\left({\\mathbf\\Psi} = (\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top, \\nu = -n \\right)\n",
    "\\end{align*}\n",
    "\n",
    "| |\n",
    "|-|\n",
    "|[an Inverse-Wishart distribution](https://en.wikipedia.org/wiki/Inverse-Wishart_distribution)|\n",
    "\n",
    "\\begin{align*}\n",
    "\\Longrightarrow p(\\boldsymbol \\Sigma | \\boldsymbol \\beta, \\mathbf{X},\\mathbf{y}) = {}& {\\frac {\\operatorname{det}({\\mathbf {\\Psi } })^{\\nu /2}}{2^{\\nu n/2}\\Gamma _{n}({\\frac {\\nu }{2}})}}\\operatorname{det}(\\boldsymbol \\Sigma)^{-(\\nu +n+1)/2}e^{-{\\frac {1}{2}}\\operatorname{tr} (\\mathbf {\\Psi } \\boldsymbol \\Sigma ^{-1})}\\hspace{1.66in}\\\\\n",
    "or \\quad {}& \\text{to use a conjugate family of priors...}\\\\\n",
    "p(\\boldsymbol \\Sigma) = {}& \\mathcal{W}^{-1}\\left(\\boldsymbol\\Psi = \\boldsymbol\\Psi_0, \\nu = n+1 \\right) \\quad \\text{ so}\\\\\n",
    "\\boldsymbol \\Sigma | \\boldsymbol \\beta, \\mathbf{X},\\mathbf{y} \\sim {}& \\mathcal{W}^{-1}\\left(\\boldsymbol\\Psi = \\boldsymbol\\Psi_0 + (\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top, \\nu = n+2 \\right)\n",
    "\\end{align*}\n",
    "\n",
    "since [determinants multiply](https://proofwiki.org/wiki/Determinant_of_Matrix_Product) and [traces add](https://proofwiki.org/wiki/Trace_of_Sum_of_Matrices_is_Sum_of_Traces#:~:text=let%20A%2BB%20denote%20the,denotes%20the%20trace%20of%20A.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c1730",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse-Wishart Distributions [10 minutes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "736401db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of freedom must be greater than the dimension of scale matrix minus 1.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; from scipy import stats\n",
    "p = 2; Psi = np.eye(p) # 2x2 identity\n",
    "try:\n",
    "    stats.invwishart(df=-p, scale=Psi)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40238cb7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So $p(\\boldsymbol \\Sigma) \\propto 1$ is an ***improper prior*** that results in an ***imporoper posterior***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a54e5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.00866829, 0.46419199],\n",
       "       [0.46419199, 0.18997762]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myIWD = stats.invwishart(df=p, scale=Psi); myIWD.rvs(1) # p-1 also won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b85b91",
   "metadata": {},
   "source": [
    "$$E[\\boldsymbol \\Sigma] = \\frac{\\boldsymbol\\Psi}{\\nu - p - 1} \\text{ for } \\boldsymbol \\Sigma \\sim \\mathcal{W}^{-1}(\\boldsymbol \\Psi,\\nu) \\text{ with } \\nu>p+1$$\n",
    "\n",
    "That's why we made the \"interesting\" choice of $\\nu = n+1$ for the ***conjugate prior*** specification above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d135ddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.39915696, 0.38525571],\n",
       "       [0.38525571, 5.21579049]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myIWD = stats.invwishart(df=p+2, scale=Psi); myIWD.rvs(size=100000).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b92138",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The LKJ (instead of Wishart) Distribution [20 minutes]\n",
    "\n",
    "The ***covariance matrix*** $\\boldsymbol \\Sigma_{p \\times p} = \\mathbf{D R D} = \\mathbf{D LL^\\top D}$ for \n",
    "- $\\mathbf{D} = \\operatorname{diag}(\\boldsymbol \\sigma)$ the ***diagonal matrix*** of ***standard deviations*** \n",
    "- $\\mathbf{R}$ the ***correlation matrix*** with all ***diagonal values*** equal to $1$, and \n",
    "- $\\mathbf{L}$ the ***lower diagonal of the Cholesky decomposition*** of $\\mathbf{R}$\n",
    "\n",
    "The ***LKJ (Lewandowski-Kurowicka-Joe) prior*** is simpler than the ***Inverse-Wishart*** and is [simple to evaluate](https://mc-stan.org/docs/functions-reference/cholesky-lkj-correlation-distribution.html) \n",
    "\n",
    "$$\\require{cancel} \n",
    "\\begin{align*}\n",
    "p(\\mathbf {R}) \\propto &{}\\det(\\mathbf{R})^{\\eta -1} \\quad f^{-1}(L)=R=LL^\\top \\quad J = \\frac{d f^{-1}(L)}{d L} = \\frac{d R}{d L} \\quad J_{ij} = \\frac{dR_i}{dL_j}\\\\\n",
    "p(\\mathbf {L}) =&{} \\det(\\mathbf{LL^\\top})^{\\eta -1} \\det(J) = \\overbrace{\\left(\\prod_{k=1}^p L_{kk}\\right)^{\\eta -1}}^{\\det(\\mathbf{L})^{\\eta -1}}\\overbrace{\\left(\\prod_{k=1}^p L_{kk}^\\top\\right)^{\\eta -1}}^{\\det(\\mathbf{L^\\top})^{\\eta -1}} \\overbrace{\\left(\\prod_{k=1}^p L_{kk}^{p-k}\\right)}^{\\det(J)} = \\prod_{k=\\cancel{1}2}^p L_{kk}^{p-k + 2(\\eta-1)}\n",
    "\\end{align*}$$\n",
    "\n",
    "and provides efficient computation of $(\\mathbf{y}-\\boldsymbol\\mu)^\\top\\boldsymbol\\Sigma^{-1}(\\mathbf{y}-\\boldsymbol\\mu) = \\epsilon^\\top L^{-\\top}L^{-1} \\epsilon = (L^{-1} \\epsilon)^\\top(L^{-1} \\epsilon) = x^\\top x$ where $x$ can be efficiently solved for based on ***lower triangular backwards substitution***  $L\\underset{L^{-1} \\epsilon}{x} = \\epsilon$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a1e49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The LKJ (instead of Wishart) Distribution [10 minutes]\n",
    "\n",
    "\n",
    "$p(\\boldsymbol \\Sigma) = p(\\boldsymbol \\sigma)p(\\mathbf {R})$ and the $\\eta=1$ \n",
    "***hyperparameter*** specifies a uniform distribution on ***correlation matrices***\n",
    "\n",
    "$$p(\\mathbf {R}) \\propto \\det(\\mathbf{R}_{p \\times p})^{\\eta -1} \\quad \\text{ $\\eta=1$ gives proper posteriors since } p(\\mathbf {R}) \\propto 1 \\text{ is not the same as }p(\\boldsymbol \\Sigma)\\propto 1 $$\n",
    "\n",
    "- The ***determinant*** is the product of the ***singular values*** and is largest when all ***singular values***<br>(which sum to $p$) are equal to $1$ which means all off-diagonal correlations are $0$\n",
    "\n",
    "Increasing $\\eta \\rightarrow \\infty$ thus favors ***correlation matrices*** with \n",
    "smaller magnitudes of component correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16053284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.38505947, 1.1126808 , 2.19180188])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymc as pm # https://www.pymc.io/projects/examples/en/latest/case_studies/LKJ.html\n",
    "# https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.LKJCholeskyCov.html\n",
    "with pm.Model() as LKJ:\n",
    "    packed_L = pm.LKJCholeskyCov(\"packed_L\", n=2, eta=2.0, \n",
    "                                 sd_dist=pm.Exponential.dist(1.0, shape=2), compute_corr=False)\n",
    "packed_L.eval()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcaa7e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.91838972, 1.54112908],\n",
       "       [1.54112908, 6.04205406]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with LKJ:\n",
    "    L = pm.expand_packed_triangular(2, packed_L)\n",
    "    Sigma = L.dot(L.T)\n",
    "Sigma.eval()#.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e91d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Multivariate Normal Inference: the MVN-LKJ model<br>*as opposed to Bayesian Linear Regression* [15 minutes]\n",
    "\n",
    "$$\\scriptsize\n",
    "\\begin{align*}\\require{cancel}\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}\\cancel{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}{\\frac{1}{\\sigma^{\\frac{n}{2}}}}\\exp \\left(-{\\frac {1}{2\\sigma^2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top\\cancel{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\\hline\\\\\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} \\cancel{= \\sigma^2I_{n\\times n}})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\\hline\\\\\n",
    "\\mathbf{y}_{i} \\sim {} & \\mathcal{MVN}(\\boldsymbol \\mu,\\boldsymbol \\Sigma = \\mathbf{DRD})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} - \\boldsymbol\\mu)^\\top{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\boldsymbol\\mu)\\right)\\\\\n",
    "\\boldsymbol\\beta \\sim {} & \\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta)\\\\\n",
    "\\mathbf {R} \\sim {}& \\mathcal{LKJ}(\\eta) & p(\\mathbf {R}) \\propto {}& \\det(\\mathbf{R}_{p \\times p})^{\\eta -1}\\\\\n",
    "\\sigma_i \\sim {} & exponential(\\lambda)\\quad \\text{ and } \\quad \\mathbf{D}=\\text{diag}(\\boldsymbol \\sigma)  & p(\\sigma_i) = {} & \\lambda e^{-\\lambda \\sigma_i}1_{[0,\\infty]}(\\sigma_i)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449185a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Multivariate Normal Inference: the MVN-LKJ model<br>*as opposed to Bayesian Linear Regression* [15 minutes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ab29ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [packed_L, mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:27&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 28 seconds.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; from scipy import stats; import pymc as pm; p=10; Psi=np.eye(p); a_cov = stats.invwishart(df=p+2, scale=Psi).rvs()\n",
    "n=1000; y=stats.multivariate_normal(mean=np.zeros(p), cov=a_cov).rvs(size=n)\n",
    "with pm.Model() as MNV_LKJ:\n",
    "    packed_L = pm.LKJCholeskyCov(\"packed_L\", n=p, eta=2.0, sd_dist=pm.Exponential.dist(1.0, shape=2), compute_corr=False)\n",
    "    L = pm.expand_packed_triangular(p, packed_L); Sigma = pm.Deterministic('Sigma', L.dot(L.T))\n",
    "    mu = pm.MvNormal('mu', mu=np.array(0), cov=np.eye(p), shape=p); \n",
    "    y = pm.MvNormal('y', mu=mu, cov=Sigma, shape=(n,1), observed=y)\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7544fd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; fig,ax = plt.subplots(1,5,figsize=(18,4)); ax[-1].imshow(a_cov); ax[-1].set_title((\"Sigma used to generate y\"))\n",
    "for chain in range(4):\n",
    "    ax[chain].imshow(idata.posterior['Sigma'].mean(axis=1)[chain]); ax[chain].set_title((\"chian\",chain,\"mean Sigma\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad2ed1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 5: Part III\n",
    "\n",
    "1. Go get data from kaggle.com and perform inference for a ***Bayesian Multivariate Normal Model***\n",
    "\n",
    "\n",
    "<SPAN STYLE=\"font-size:18.0pt\">\n",
    "\n",
    "```python\n",
    "import numpy as np; from scipy import stats\n",
    "p=10; Psi=np.eye(p); a_cov = stats.invwishart(df=p+2, scale=Psi).rvs(1)\n",
    "n=1000; y=stats.multivariate_normal(mean=np.zeros(p), cov=a_cov).rvs(size=n)\n",
    "# Replace this made up data with your data set from kaggle...\n",
    "    \n",
    "with pm.Model() as MNV_LKJ:\n",
    "    packed_L = pm.LKJCholeskyCov(\"packed_L\", n=p, eta=2.0,\n",
    "                                 sd_dist=pm.Exponential.dist(1.0, shape=2), compute_corr=False)\n",
    "    L = pm.expand_packed_triangular(p, packed_L)\n",
    "    Sigma = pm.Deterministic('Sigma', L.dot(L.T))\n",
    "    mu = pm.MvNormal('mu', mu=np.array(0), cov=np.eye(p), shape=p); \n",
    "    y = pm.MvNormal('y', mu=mu, cov=Sigma, shape=(n,1), observed=y)\n",
    "    \n",
    "with MNV_LKJ    \n",
    "    idata = pm.sample()\n",
    "```    \n",
    "</SPAN>\n",
    "    \n",
    "2. Specify ***priors*** that work: certainly you'll likely need to change the ***prior hyperparameters*** for $\\boldsymbol \\mu$ (`mu`) and $\\mathbf{R}$ (`packed_L`)...\n",
    "    1. And you could consider adjusting the ***prior*** for $\\boldsymbol \\sigma$ using `sd_dist`... \n",
    "\n",
    "3. [Optional] Assess the performance of the MCMC and note any issue\n",
    "\n",
    "    1. Traceplots, inference (credible) intervals, effective sample sizes, energy plots, warnings and other notes... just the usual stuff they do [here](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_overview.html#pymc-overview)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
