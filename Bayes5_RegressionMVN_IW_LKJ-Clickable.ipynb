{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222e602a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Quiz [15 minutes]\n",
    "\n",
    "1. List the assumptions implied by the ***linear regression model*** specification\n",
    "\n",
    "   $$y_i \\sim \\mathcal N(\\mathbf{x}_i^\\top \\boldsymbol \\beta,\\sigma^2), i=1,\\cdots,n$$\n",
    "\n",
    "2. Rewrite the above expression as a single sample from a ***multivariate normal distribution*** using the ***multivariate random variable*** $\\mathbf{y}_{n\\times 1}$, ***design matrix*** $X_{n\\times p}$, and ***parameters*** $\\boldsymbol \\beta_{p \\times 1}$ and $\\boldsymbol \\Sigma_{n \\times n} = \\sigma^2 I_{n \\times n}$ (and include all the dimensions in your expression)\n",
    "\n",
    "3. Write down the mathematical expression of the PDF of the above ***linear regression model*** as a ***multivariate normal distribution*** in terms of $\\boldsymbol \\Sigma_{n \\times n}$ (instead of $\\sigma^2 I_{n \\times n}$) (and feel free to look up the expression of the pdf online if needed)\n",
    "\n",
    "4. What family of ***priors*** would be ***conjugate*** for the ***multivariate parameter*** $\\boldsymbol \\beta$ for this ***linear regression model***?\n",
    "\n",
    "5. What mathmematical form would a ***conjugate prior*** for the ***covariance matrix*** $\\boldsymbol \\Sigma$ (as opposed to $\\sigma^2$ as in $\\sigma^2I$) be proporitional to  for this ***linear regression model***? \n",
    "\n",
    "   Hint: \n",
    "\n",
    "   $$(\\mathbf {y} -\\mathbf{X \\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol \\beta}) = \\textrm{tr}\\left((\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol \\beta}) \\right) = \\textrm{tr}\\left((\\mathbf {y} - \\mathbf{X\\boldsymbol \\beta})(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1} \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd0f3df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Solutions [5 minutes]\n",
    "\n",
    "1. Assumptions of ***Linear Regression***\n",
    "   \n",
    "   A. indepedendent error terms $\\quad$ B. normally distributed error terms $\\quad$ C.homoskedastic error terms\n",
    "   \n",
    "   D. linear form and $\\mathbf{x_i}$ having no randomness (measured without error)\n",
    "\n",
    "\n",
    "2. ***Multivariate Normal Distribution*** specification of muliple linear regression\n",
    "\n",
    "   $\\mathbf{y}_{n\\times 1} \\sim \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})$\n",
    "   \n",
    "\n",
    "3. <font style='color:white'>For ***positive definite*** $\\Sigma$</font>\n",
    "\n",
    "   <span style='color:white'>\n",
    "\n",
    "   $$\\begin{align*}p(\\textbf{y}_{n\\times 1}) =  {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right) \n",
    "   \\propto \\exp \\left(-{\\frac {1}{2}}( {\\boldsymbol \\beta^\\top}\\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{X\\boldsymbol \\beta} - 2{\\boldsymbol \\beta^\\top}\\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{y} \\right)\\\\ \\propto {}& \n",
    "    \\exp \\left(-{\\frac {1}{2}}\\left( \\boldsymbol \\beta - (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y}\\right)^\\top \\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{X} \\left( \\boldsymbol \\beta - (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y)}\\right) \\right) \\quad \\underbrace{\\mathbf{ y} = \\mathbf{ \\hat y} + \\hat  {\\boldsymbol \\epsilon} \\;\\;\\text{ and }\\;\\;  \\mathbf{X^\\top} \\overbrace{{\\Sigma }^{-1}}^{\\sigma^{-2}I} \\hat {\\boldsymbol \\epsilon} }_{\\mathbf{ \\hat y} \\, =\\, \\mathbf{X}(\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y} \\;  \\Longrightarrow \\; \\mathbf{X}^\\top \\mathbf{ \\hat y} \\,=\\, \\mathbf{X}^\\top \\mathbf{y}} = \\mathbf{0}\n",
    "    \\end{align*}$$\n",
    "\n",
    "   </span>\n",
    "    \n",
    "4. <font style='color:white'>The ***conjugate prior*** for $\\boldsymbol \\beta$ would be $\\boldsymbol \\beta \\sim \\mathcal{MVN}(\\boldsymbol \\beta_0, \\boldsymbol\\Sigma_\\beta)$</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c63dfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Solutions [5 minutes]\n",
    "\n",
    "1. Assumptions of ***Linear Regression***\n",
    "   \n",
    "   A. indepedendent error terms $\\quad$ B. normally distributed error terms $\\quad$ C.homoskedastic error terms\n",
    "   \n",
    "   D. linear form and $\\mathbf{x_i}$ having no randomness (measured without error)\n",
    "\n",
    "\n",
    "2. ***Multivariate Normal Distribution*** specification of muliple linear regression\n",
    "\n",
    "   $\\mathbf{y}_{n\\times 1} \\sim \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})$\n",
    "   \n",
    "\n",
    "3. For ***positive definite*** $\\Sigma$\n",
    "\n",
    "   $$\\begin{align*}p(\\textbf{y}_{n\\times 1}) =  {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right) \n",
    "   \\propto \\exp \\left(-{\\frac {1}{2}}( {\\boldsymbol \\beta^\\top}\\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{X\\boldsymbol \\beta} - 2{\\boldsymbol \\beta^\\top}\\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{y} \\right)\\\\ \\color{white}{\\propto} {}& \n",
    "    \\color{white}{\\exp \\left(-{\\frac {1}{2}}\\left( \\boldsymbol \\beta - (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y}\\right)^\\top \\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{X} \\left( \\boldsymbol \\beta - (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y)}\\right) \\right) \\quad \\underbrace{\\mathbf{ y} = \\mathbf{ \\hat y} + \\hat  {\\boldsymbol \\epsilon} \\;\\;\\text{ and }\\;\\;  \\mathbf{X^\\top} \\overbrace{{\\Sigma }^{-1}}^{\\sigma^{-2}I} \\hat {\\boldsymbol \\epsilon} }_{\\mathbf{ \\hat y} \\, =\\, \\mathbf{X}(\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y} \\;  \\Longrightarrow \\; \\mathbf{X}^\\top \\mathbf{ \\hat y} \\,=\\, \\mathbf{X}^\\top \\mathbf{y}} = \\mathbf{0}}\n",
    "    \\end{align*}$$\n",
    "\n",
    "    \n",
    "4. <font style='color:white'>The ***conjugate prior*** for $\\boldsymbol \\beta$ would be $\\boldsymbol \\beta \\sim \\mathcal{MVN}(\\boldsymbol \\beta_0, \\boldsymbol\\Sigma_\\beta)$</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a05d9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Solutions [5 minutes]\n",
    "\n",
    "1. Assumptions of ***Linear Regression***\n",
    "   \n",
    "   A. indepedendent error terms $\\quad$ B. normally distributed error terms $\\quad$ C.homoskedastic error terms\n",
    "   \n",
    "   D. linear form and $\\mathbf{x_i}$ having no randomness (measured without error)\n",
    "\n",
    "\n",
    "2. ***Multivariate Normal Distribution*** specification of muliple linear regression\n",
    "\n",
    "   $\\mathbf{y}_{n\\times 1} \\sim \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})$\n",
    "   \n",
    "\n",
    "3. For ***positive definite*** $\\Sigma$\n",
    "\n",
    "   $$\\begin{align*}p(\\textbf{y}_{n\\times 1}) =  {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right) \n",
    "   \\propto \\exp \\left(-{\\frac {1}{2}}( {\\boldsymbol \\beta^\\top}\\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{X\\boldsymbol \\beta} - 2{\\boldsymbol \\beta^\\top}\\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{y} \\right)\\\\ \\propto {}& \n",
    "    \\exp \\left(-{\\frac {1}{2}}\\left( \\boldsymbol \\beta - (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y}\\right)^\\top \\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{X} \\left( \\boldsymbol \\beta - (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y)}\\right) \\right) \\quad \\underbrace{\\mathbf{ y} = \\mathbf{ \\hat y} + \\hat  {\\boldsymbol \\epsilon} \\;\\;\\text{ and }\\;\\;  \\mathbf{X^\\top} \\overbrace{{\\Sigma }^{-1}}^{\\sigma^{-2}I} \\hat {\\boldsymbol \\epsilon} }_{\\mathbf{ \\hat y} \\, =\\, \\mathbf{X}(\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y} \\;  \\Longrightarrow \\; \\mathbf{X}^\\top \\mathbf{ \\hat y} \\,=\\, \\mathbf{X}^\\top \\mathbf{y}} = \\mathbf{0}\n",
    "    \\end{align*}$$\n",
    "\n",
    "4. The ***conjugate prior*** for $\\boldsymbol \\beta$ would be <font style='color:white'>$\\boldsymbol \\beta \\sim \\mathcal{MVN}(\\boldsymbol \\beta_0, \\boldsymbol\\Sigma_\\beta)$</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a4e3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Solutions [0 minutes]\n",
    "\n",
    "1. Assumptions of ***Linear Regression***\n",
    "   \n",
    "   A. indepedendent error terms $\\quad$ B. normally distributed error terms $\\quad$ C.homoskedastic error terms\n",
    "   \n",
    "   D. linear form and $\\mathbf{x_i}$ having no randomness (measured without error)\n",
    "\n",
    "\n",
    "2. ***Multivariate Normal Distribution*** specification of muliple linear regression\n",
    "\n",
    "   $\\mathbf{y}_{n\\times 1} \\sim \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})$\n",
    "   \n",
    "\n",
    "3. For ***positive definite*** $\\Sigma$\n",
    "\n",
    "   $$\\begin{align*}p(\\textbf{y}_{n\\times 1}) =  {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right) \n",
    "   \\propto \\exp \\left(-{\\frac {1}{2}}( {\\boldsymbol \\beta^\\top}\\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{X\\boldsymbol \\beta} - 2{\\boldsymbol \\beta^\\top}\\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{y} \\right)\\\\ \\propto {}& \n",
    "    \\exp \\left(-{\\frac {1}{2}}\\left( \\boldsymbol \\beta - (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y}\\right)^\\top \\mathbf{X^\\top}{\\boldsymbol {\\Sigma }}^{-1} \\mathbf{X} \\left( \\boldsymbol \\beta - (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y)}\\right) \\right) \\quad \\underbrace{\\mathbf{ y} = \\mathbf{ \\hat y} + \\hat  {\\boldsymbol \\epsilon} \\;\\;\\text{ and }\\;\\;  \\mathbf{X^\\top} \\overbrace{{\\Sigma }^{-1}}^{\\sigma^{-2}I} \\hat {\\boldsymbol \\epsilon} }_{\\mathbf{ \\hat y} \\, =\\, \\mathbf{X}(\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y} \\;  \\Longrightarrow \\; \\mathbf{X}^\\top \\mathbf{ \\hat y} \\,=\\, \\mathbf{X}^\\top \\mathbf{y}} = \\mathbf{0}\n",
    "    \\end{align*}$$\n",
    "\n",
    "4. The ***conjugate prior*** for $\\boldsymbol \\beta$ would be $\\boldsymbol \\beta \\sim \\mathcal{MVN}(\\boldsymbol \\beta_0, \\boldsymbol\\Sigma_\\beta)$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48925b7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Solutions [5 minutes]\n",
    "\n",
    "1. Assumptions of ***Linear Regression***\n",
    "   \n",
    "   A. indepedendent error terms $\\quad$ B. normally distributed error terms $\\quad$ C.homoskedastic error terms\n",
    "   \n",
    "   D. linear form and $\\mathbf{x_i}$ having no randomness (measured without error)\n",
    "\n",
    "\n",
    "2. ***Multivariate Normal Distribution*** specification of muliple linear regression\n",
    "\n",
    "   $\\mathbf{y}_{n\\times 1} \\sim \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})$\n",
    "\n",
    "\n",
    "3. For ***positive definite*** $\\Sigma$\n",
    "\n",
    "   $$\\begin{align*}p(\\textbf{y}_{n\\times 1}) =  {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}\\text{tr}\\left((\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\right) \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\\\ \n",
    "\\propto {}& \n",
    "\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}\\text{tr}\\left((\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}\\right)\\right)\n",
    "    \\end{align*}$$\n",
    "\n",
    "4.  <font style='color:gray'>The ***conjugate prior*** for $\\boldsymbol \\beta$ would be $\\boldsymbol \\beta \\sim \\mathcal{MVN}(\\boldsymbol \\beta_0, \\boldsymbol\\Sigma_\\beta)$</font>\n",
    "\n",
    "5. The ***conjugate prior*** for $\\boldsymbol \\Sigma$ would be $p(\\boldsymbol \\Sigma) \\propto \\color{white}{\\det({\\boldsymbol {\\Sigma }})^{-v/2} \\exp \\left(-{\\frac {1}{2}}\\textrm{tr}\\left(\\Psi{\\boldsymbol {\\Sigma }}^{-1} \\right)\\right)}$ \n",
    "\n",
    "   <font style='color:white'>an [Inverse-Wishart distribution] and it is ***conjugate*** since [determinants multiply] and [traces add]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a42ef92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Activity 5: Solutions [0 minutes]\n",
    "\n",
    "1. Assumptions of ***Linear Regression***\n",
    "   \n",
    "   A. indepedendent error terms $\\quad$ B. normally distributed error terms $\\quad$ C.homoskedastic error terms\n",
    "   \n",
    "   D. linear form and $\\mathbf{x_i}$ having no randomness (measured without error)\n",
    "\n",
    "\n",
    "2. ***Multivariate Normal Distribution*** specification of muliple linear regression\n",
    "\n",
    "   $\\mathbf{y}_{n\\times 1} \\sim \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})$\n",
    "\n",
    "\n",
    "3. For ***positive definite*** $\\Sigma$\n",
    "\n",
    "   $$\\begin{align*}p(\\textbf{y}_{n\\times 1}) =  {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}\\text{tr}\\left((\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\right) \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\\\ \n",
    "\\propto {}& \n",
    "\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}\\text{tr}\\left((\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})(\\mathbf {y} -\\mathbf{X\\boldsymbol \\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}\\right)\\right)\n",
    "    \\end{align*}$$\n",
    "\n",
    "4.  <font style='color:gray'>The ***conjugate prior*** for $\\boldsymbol \\beta$ would be $\\boldsymbol \\beta \\sim \\mathcal{MVN}(\\boldsymbol \\beta_0, \\boldsymbol\\Sigma_\\beta)$</font>\n",
    "\n",
    "5. The ***conjugate prior*** for $\\boldsymbol \\Sigma$ would be $p(\\boldsymbol \\Sigma) \\propto \\det({\\boldsymbol {\\Sigma }})^{-v/2} \\exp \\left(-{\\frac {1}{2}}\\textrm{tr}\\left(\\Psi{\\boldsymbol {\\Sigma }}^{-1} \\right)\\right)$ \n",
    "\n",
    "   an [Inverse-Wishart distribution](https://en.wikipedia.org/wiki/Inverse-Wishart_distribution) and it is ***conjugate*** since [determinants multiply](https://proofwiki.org/wiki/Determinant_of_Matrix_Product) and [traces add](https://proofwiki.org/wiki/Trace_of_Sum_of_Matrices_is_Sum_of_Traces#:~:text=let%20A%2BB%20denote%20the,denotes%20the%20trace%20of%20A.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f761f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Linear Regression:<br>Multivariate Normal Distributions [10 minutes]\n",
    "\n",
    "\n",
    "\\begin{align*}\\require{cancel}\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}\\cancel{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}{\\frac{1}{\\sigma^{\\frac{n}{2}}}}\\exp \\left(-{\\frac {1}{2\\sigma^2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top\\cancel{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\n",
    "\\boldsymbol\\beta \\sim {} & \\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta) \\quad or\\;?\\\\\\\\\n",
    "\\sigma \\sim {} & exponential(\\lambda)  \\quad p(\\sigma) =  \\lambda e^{-\\lambda \\sigma}1_{[0,\\infty]}(\\sigma)\\\\\\\\\n",
    "\\end{align*}\n",
    "$$or \\quad \\sigma \\sim \\text{HalfNormal}(\\mu_\\sigma,\\sigma_\\sigma), \\sigma \\sim  \\text{InverseGamma}(\\alpha,\\beta), \\sigma \\sim \\text{TruncatedNormal}(\\mu_\\sigma,\\sigma_\\sigma,a,b) \\quad or \\; ?$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0790533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [betas, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 12 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm; import numpy as np; n,p=100,10; X,y=np.zeros((n,p)),np.ones((n,1))\n",
    "with pm.Model() as MLR:\n",
    "    betas = pm.MvNormal('betas', mu=np.zeros((p,1)), cov=np.eye(p), shape=(p,1))\n",
    "    sigma = pm.TruncatedNormal('sigma', mu=1, sigma=1, lower=0) # it's just a half normal, actually\n",
    "    y = pm.Normal('y', mu=pm.math.dot(X, betas), sigma=sigma, observed=y)\n",
    "    # y = pm.MvNormal('y', mu=X@betas, cov=sigma**2*np.eye(n), shape=(n,1), observed=y)\n",
    "    \n",
    "with MLR:\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389faa1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 5: Part I\n",
    "\n",
    "1. Go get data from kaggle.com and do a ***Bayesian Linear Regression*** analysis\n",
    "\n",
    "```python\n",
    "import pymc as pm; import numpy as np\n",
    "n,p=100,10; X,y=np.zeros((n,p)),np.ones((n,1))\n",
    "# Replace this made up data with your data set from kaggle...\n",
    "with pm.Model() as MLR:\n",
    "    betas = pm.MvNormal('betas', mu=np.zeros((p,1)), cov=np.eye(p), shape=(p,1))\n",
    "    sigma = pm.TruncatedNormal('sigma', mu=1, sigma=1, lower=0) # half normal\n",
    "    y = pm.Normal('y', mu=pm.math.dot(X, betas), sigma=sigma, observed=y)\n",
    "\n",
    "with MLR:\n",
    "    idata = pm.sample()\n",
    "```    \n",
    "\n",
    "2. Choose ***prior*** that are sensible: certainly you might change the ***hyperparameters***, and perhaps you can experiment with different distributional families for `sigma`...\n",
    "\n",
    "3. [Optional] Assess the performance of the MCMC and note any issues or warnings\n",
    "\n",
    "    1. Traceplots, inference (credible) intervals, effective sample sizes, energy plots, warnings and other notes... just the usual stuff they do [here](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_overview.html#pymc-overview)\n",
    "\n",
    "4. [Optional] Perform ***Multiple Linear Regression*** diagnostics... residual plots, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5afef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Linear Regression?<br>Geneal $\\boldsymbol \\Sigma$ Instead of $\\sigma^2I$ [10 minutes]\n",
    "\n",
    "\\begin{align*}\\require{cancel}\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}\\cancel{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}{\\frac{1}{\\sigma^{\\frac{n}{2}}}}\\exp \\left(-{\\frac {1}{2\\sigma^2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top\\cancel{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\hline\\\\\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} \\cancel{= \\sigma^2I_{n\\times n}})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\n",
    "\\boldsymbol\\beta \\sim {} & \\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta) \\quad or\\;?\\\\\\\\\n",
    "p(\\boldsymbol \\Sigma) \\propto {} & \\det({\\boldsymbol {\\Sigma }})^{-v/2} \\exp \\left(-{\\frac {1}{2}}\\textrm{tr}\\left(\\Psi{\\boldsymbol {\\Sigma }}^{-1} \\right)\\right) \\quad or\\;?\n",
    "\\end{align*}\n",
    "\n",
    "## Do we forsee any problems with what we're going to do here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96587f97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conjugate Multivariate Normal Priors [3 minutes]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\boldsymbol \\Sigma, \\mathbf{X})= {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "\\propto{}& \\exp\\left(\\mathbf{\\beta}^\\top\\mathbf{X}^\\top\\boldsymbol\\Sigma^{-1}\\mathbf{y} - \\frac{1}{2}\\mathbf{\\beta}^\\top \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X\\beta} \\right)\\\\\n",
    "\\color{white}{\\propto{}}& \\color{white}{\\exp\\left( - \\frac{1}{2} \\left((\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} -\\beta\\right)^{\\!\\top} \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]\\left((\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} -\\beta\\right)  \\right)}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta) \\propto 1 \\Longrightarrow} {}& \\color{white}{p(\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = \\mathcal{MVN}\\left(E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}, \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]^{-1} \\right)}\\\\\n",
    "\\color{white}{or} \\quad {}& \\color{white}{\\text{to use a conjugate family of priors...}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta) =} {}& \\color{white}{\\mathcal{MVN}\\left(E[\\boldsymbol \\beta ] = \\boldsymbol \\beta_0, \\text{Cov}[\\boldsymbol \\beta ] = \\boldsymbol \\Sigma_\\beta \\right) \\quad \\text{ so}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})} \\color{white}{=} {}& \\color{white}{\\mathcal{MVN}\\left(\\overset{E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] \\; = \\quad\\quad}{\\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]^{-1}}\\bigg( \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} + \\boldsymbol \\Sigma_\\beta^{-1}\\boldsymbol\\beta_0 \\right), \\text{Var}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top}\\boldsymbol \\Sigma^{-1} \\mathbf{X} + \\boldsymbol \\Sigma_\\beta^{-1}  \\right]^{-1} \\bigg)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "<span style='color:white'>\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Look familiar?}&\\, \\Downarrow{} \\quad\\quad\\quad \\underbrace{\\;\\,\\textbf{mean}\\,\\;}\\quad\\;\\underbrace{\\textbf{precision}}\\\\\n",
    "p(\\theta|x,\\theta_0,\\tau, \\phi) &={} \\text{N}\\left(\\frac{\\left(\\tau \\theta_0+\\phi\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau+n\\phi)}, \\tau+n\\phi \\right)\n",
    "\\end{align*}\n",
    "\n",
    "</span>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d6151",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conjugate Multivariate Normal Priors [3 minutes]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\boldsymbol \\Sigma, \\mathbf{X})= {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "\\propto{}& \\exp\\left(\\mathbf{\\beta}^\\top\\mathbf{X}^\\top\\boldsymbol\\Sigma^{-1}\\mathbf{y} - \\frac{1}{2}\\mathbf{\\beta}^\\top \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X\\beta} \\right)\\\\\n",
    "\\propto{}& \\exp\\left( - \\frac{1}{2} \\left(\\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} \\right)^{\\!\\top} \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]\\left(\\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} \\right)  \\right)\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta) \\propto 1 \\Longrightarrow} {}& \\color{white}{p(\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = \\mathcal{MVN}\\left(E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}, \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]^{-1} \\right)}\\\\\n",
    "\\color{white}{or} \\quad {}& \\color{white}{\\text{to use a conjugate family of priors...}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta) =} {}& \\color{white}{\\mathcal{MVN}\\left(E[\\boldsymbol \\beta ] = \\boldsymbol \\beta_0, \\text{Var}[\\boldsymbol \\beta ] = \\boldsymbol \\Sigma_\\beta \\right) \\quad \\text{ so}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})} \\color{white}{=} {}& \\color{white}{\\mathcal{MVN}\\left(\\overset{E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] \\; = \\quad\\quad}{\\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]^{-1}}\\bigg( \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} + \\boldsymbol \\Sigma_\\beta^{-1}\\boldsymbol\\beta_0 \\right), \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top}\\boldsymbol \\Sigma^{-1} \\mathbf{X} + \\boldsymbol \\Sigma_\\beta^{-1} \\right]^{-1}  \\bigg)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "<span style='color:white'>\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Look familiar?}&\\, \\Downarrow{} \\quad\\quad\\quad \\underbrace{\\;\\,\\textbf{mean}\\,\\;}\\quad\\;\\underbrace{\\textbf{precision}}\\\\\n",
    "p(\\theta|x,\\theta_0,\\tau, \\phi) &={} \\text{N}\\left(\\frac{\\left(\\tau \\theta_0+\\phi\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau+n\\phi)}, \\tau+n\\phi \\right)\n",
    "\\end{align*}\n",
    "\n",
    "</span>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc0ef7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conjugate Multivariate Normal Priors [2 minutes]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\boldsymbol \\Sigma, \\mathbf{X})= {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "\\propto{}& \\exp\\left(\\mathbf{\\beta}^\\top\\mathbf{X}^\\top\\boldsymbol\\Sigma^{-1}\\mathbf{y} - \\frac{1}{2}\\mathbf{\\beta}^\\top \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X\\beta} \\right)\\\\\n",
    "\\propto{}& \\exp\\left( - \\frac{1}{2} \\left(\\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} \\right)^{\\!\\top} \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]\\left(\\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} \\right)  \\right)\\\\\n",
    "p(\\boldsymbol \\beta) \\propto 1 \\Longrightarrow {}& \\color{white}{p(\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = \\mathcal{MVN}\\left(E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}, \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]^{-1} \\right)}\\\\\n",
    "\\color{white}{or} \\quad {}& \\color{white}{\\text{to use a conjugate family of priors...}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta) =} {}& \\color{white}{\\mathcal{MVN}\\left(E[\\boldsymbol \\beta ] = \\boldsymbol \\beta_0, \\text{Var}[\\boldsymbol \\beta ] = \\boldsymbol \\Sigma_\\beta \\right) \\quad \\text{ so}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})} \\color{white}{=} {}& \\color{white}{\\mathcal{MVN}\\left(\\overset{E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] \\; = \\quad\\quad}{\\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]^{-1}}\\bigg( \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} + \\boldsymbol \\Sigma_\\beta^{-1}\\boldsymbol\\beta_0 \\right), \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top}\\boldsymbol \\Sigma^{-1} \\mathbf{X}  + \\boldsymbol \\Sigma_\\beta^{-1} \\right]^{-1} \\bigg)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "<span style='color:white'>\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Look familiar?}&\\, \\Downarrow{} \\quad\\quad\\quad \\underbrace{\\;\\,\\textbf{mean}\\,\\;}\\quad\\;\\underbrace{\\textbf{precision}}\\\\\n",
    "p(\\theta|x,\\theta_0,\\tau, \\phi) &={} \\text{N}\\left(\\frac{\\left(\\tau \\theta_0+\\phi\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau+n\\phi)}, \\tau+n\\phi \\right)\n",
    "\\end{align*}\n",
    "\n",
    "</span>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286e2ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conjugate Multivariate Normal Priors [1 minute]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\boldsymbol \\Sigma, \\mathbf{X})= {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "\\propto{}& \\exp\\left(\\mathbf{\\beta}^\\top\\mathbf{X}^\\top\\boldsymbol\\Sigma^{-1}\\mathbf{y} - \\frac{1}{2}\\mathbf{\\beta}^\\top \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X\\beta} \\right)\\\\\n",
    "\\propto{}& \\exp\\left( - \\frac{1}{2} \\left(\\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} \\right)^{\\!\\top} \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]\\left(\\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} \\right)  \\right)\\\\\n",
    "p(\\boldsymbol \\beta) \\propto 1 \\Longrightarrow {}& p(\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = \\mathcal{MVN}\\left(E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}, \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]^{-1} \\right)\\\\\n",
    "\\color{white}{or} \\quad {}& \\color{white}{\\text{to use a conjugate family of priors...}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta) =} {}& \\color{white}{\\mathcal{MVN}\\left(E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y} ] = \\boldsymbol \\beta_0, \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y} ] = \\boldsymbol \\Sigma_\\beta \\right) \\quad \\text{ so}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})} \\color{white}{=} {}& \\color{white}{\\mathcal{MVN}\\left(\\overset{E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] \\; = \\quad\\quad}{\\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]^{-1}}\\bigg( \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} + \\boldsymbol \\Sigma_\\beta^{-1}\\boldsymbol\\beta_0 \\right), \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top}\\boldsymbol \\Sigma^{-1} \\mathbf{X}  + \\boldsymbol \\Sigma_\\beta^{-1} \\right]^{-1} \\bigg)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "<span style='color:white'>\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Look familiar?}&\\, \\Downarrow{} \\quad\\quad\\quad \\underbrace{\\;\\,\\textbf{mean}\\,\\;}\\quad\\;\\underbrace{\\textbf{precision}}\\\\\n",
    "p(\\theta|x,\\theta_0,\\tau, \\phi) &={} \\text{N}\\left(\\frac{\\left(\\tau \\theta_0+\\phi\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau+n\\phi)}, \\tau+n\\phi \\right)\n",
    "\\end{align*}\n",
    "\n",
    "</span>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ded3bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conjugate Multivariate Normal Priors [1 minute]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\boldsymbol \\Sigma, \\mathbf{X})= {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "\\propto{}& \\exp\\left(\\mathbf{\\beta}^\\top\\mathbf{X}^\\top\\boldsymbol\\Sigma^{-1}\\mathbf{y} - \\frac{1}{2}\\mathbf{\\beta}^\\top \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X\\beta} \\right)\\\\\n",
    "\\propto{}& \\exp\\left( - \\frac{1}{2} \\left(\\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} \\right)^{\\!\\top} \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]\\left(\\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} \\right)  \\right)\\\\\n",
    "p(\\boldsymbol \\beta) \\propto 1 \\Longrightarrow {}& p(\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = \\mathcal{MVN}\\left(E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}, \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]^{-1} \\right)\\\\\n",
    "or \\quad {}& \\text{to use a conjugate family of priors...}\\\\\n",
    "p(\\boldsymbol \\beta) = {}& \\mathcal{MVN}\\left(E[\\boldsymbol \\beta] = \\boldsymbol \\beta_0, \\text{Cov}[\\boldsymbol \\beta ] = \\boldsymbol \\Sigma_\\beta \\right) \\quad \\text{ so}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})} \\color{white}{=} {}& \\color{white}{\\mathcal{MVN}\\left(\\overset{E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] \\; = \\quad\\quad}{\\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]^{-1}} \\bigg( \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} + \\boldsymbol \\Sigma_\\beta^{-1}\\boldsymbol\\beta_0 \\right), \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top}\\boldsymbol \\Sigma^{-1} \\mathbf{X} + \\boldsymbol \\Sigma_\\beta^{-1} \\right]^{-1} \\bigg)}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "<span style='color:white'>\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Look familiar?}&\\, \\Downarrow{} \\quad\\quad\\quad \\underbrace{\\;\\,\\textbf{mean}\\,\\;}\\quad\\;\\underbrace{\\textbf{precision}}\\\\\n",
    "p(\\theta|x,\\theta_0,\\tau, \\phi) &={} \\text{N}\\left(\\frac{\\left(\\tau \\theta_0+\\phi\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau+n\\phi)}, \\tau+n\\phi \\right)\n",
    "\\end{align*}\n",
    "\n",
    "</span>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a20ada",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conjugate Multivariate Normal Priors [5 minutes]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\boldsymbol \\Sigma, \\mathbf{X})= {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "\\propto{}& \\exp\\left(\\mathbf{\\beta}^\\top\\mathbf{X}^\\top\\boldsymbol\\Sigma^{-1}\\mathbf{y} - \\frac{1}{2}\\mathbf{\\beta}^\\top \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X\\beta} \\right)\\\\\n",
    "\\propto{}& \\exp\\left( - \\frac{1}{2} \\left( \\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}\\right)^{\\!\\top} \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]\\left( \\beta - (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}\\right)  \\right)\\\\\n",
    "p(\\boldsymbol \\beta) \\propto 1 \\Longrightarrow {}& p(\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = \\mathcal{MVN}\\left(E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = (\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1} \\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y}, \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top} \\boldsymbol\\Sigma^{-1} \\mathbf{X} \\right]^{-1} \\right)\\\\\n",
    "or \\quad {}& \\text{to use a conjugate family of priors...}\\\\\n",
    "p(\\boldsymbol \\beta) = {}& \\mathcal{MVN}\\left(E[\\boldsymbol \\beta ] = \\boldsymbol \\beta_0, \\text{Cov}[\\boldsymbol \\beta ] = \\boldsymbol \\Sigma_\\beta \\right) \\quad \\text{ so}\\\\\n",
    "p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}) = {}& \\mathcal{MVN}\\left(\\overset{E[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] \\; = \\quad\\quad}{\\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]}\\bigg( \\mathbf{X}^\\top \\boldsymbol\\Sigma^{-1}\\mathbf{y} + \\boldsymbol \\Sigma_\\beta^{-1}\\boldsymbol\\beta_0 \\right), \\text{Cov}[\\boldsymbol \\beta | \\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\left[\\mathbf{X}^{\\top}\\boldsymbol \\Sigma^{-1} \\mathbf{X}  + \\boldsymbol \\Sigma_\\beta^{-1} \\right]^{-1} \\bigg)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Look familiar?}&\\, \\Downarrow{} \\quad\\quad\\quad \\underbrace{\\;\\,\\textbf{mean}\\,\\;}\\quad\\;\\underbrace{\\textbf{precision}}\\\\\n",
    "p(\\theta|x,\\theta_0,\\tau, \\phi) &={} \\text{N}\\left(\\frac{\\left(\\tau \\theta_0+\\phi\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau+n\\phi)}, \\tau+n\\phi \\right)\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d8081",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 5: Part II\n",
    "    \n",
    "## Answer the following with respect to $p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})$ on the previous slide\n",
    "    \n",
    "1. Rewrite $p(\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y})$ in terms of $\\sigma^2$ (no longer using $\\Sigma$) if $\\Sigma=\\sigma^2I$\n",
    "\n",
    "2. What is $E[\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]$?\n",
    "\n",
    "3. What ***hyperparameters*** values (legal or illegal) would make $E[\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = (\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y}$?\n",
    "\n",
    "4. What ***hyperparameters*** values (legal or illegal) would make $E[  \\mathbf{\\hat y} = \\mathbf{X}\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}] = \\mathbf{X}(\\mathbf{X^\\top X})^{-1}\\mathbf{X^\\top y}$?\n",
    "\n",
    "5. What is $\\text{Var}[\\boldsymbol \\beta |\\boldsymbol\\Sigma, \\mathbf{X},\\mathbf{y}]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97b1f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse-Wishart Conjugate Priors for $\\Sigma$ [7 minutes]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\Sigma, \\mathbf{X}) = {}& (2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "= {}& (2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}} \\textrm{tr}\\big((\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\big)\\right)\\\\\n",
    "= {}& (2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}} \\textrm{tr}\\big((\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}\\big)\\right)\\\\\n",
    "p(\\boldsymbol \\Sigma) \\propto 1 \\Longrightarrow {}& \n",
    "\\boldsymbol \\Sigma | \\boldsymbol \\beta, \\mathbf{X},\\mathbf{y} \\sim \\mathcal{W}^{-1}\\left({\\mathbf\\Psi} = (\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top, \\nu = -n \\right)\n",
    "\\end{align*}\n",
    "\n",
    "| |\n",
    "|-|\n",
    "|[an Inverse-Wishart distribution](https://en.wikipedia.org/wiki/Inverse-Wishart_distribution)|\n",
    "\n",
    "\\begin{align*}\n",
    "\\color{white}{\\Longrightarrow p(\\boldsymbol \\Sigma ) =} {}& \\color{white}{{\\frac {\\operatorname{det}({\\mathbf {\\Psi } })^{\\nu /2}}{2^{\\nu n/2}\\Gamma _{n}({\\frac {\\nu }{2}})}}\\operatorname{det}(\\boldsymbol \\Sigma)^{-(\\nu +n+1)/2}e^{-{\\frac {1}{2}}\\operatorname{tr} (\\mathbf {\\Psi } \\boldsymbol \\Sigma ^{-1})}\\hspace{1.66in}}\\\\\n",
    "\\color{white}{or} \\quad {}& \\color{white}{\\text{to use a conjugate family of priors...}}\\\\\n",
    "\\color{white}{p(\\boldsymbol \\Sigma) =} {}& \\color{white}{\\mathcal{W}^{-1}\\left(\\boldsymbol\\Psi = \\boldsymbol\\Psi_0, \\nu = n+1 \\right) \\quad \\text{ so}}\\\\\n",
    "\\color{white}{\\boldsymbol \\Sigma | \\boldsymbol \\beta, \\mathbf{X},\\mathbf{y} \\sim }{}& \n",
    "\\color{white}{mathcal{W}^{-1}\\left(\\boldsymbol\\Psi = \\boldsymbol\\Psi_0 + (\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top, \\nu = n+2 \\right)}\n",
    "\\end{align*}\n",
    "\n",
    "<font style='color:white'>since [determinants multiply] and [traces add]</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf454a4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse-Wishart Conjugate Priors for $\\Sigma$ [8 minutes]\n",
    "\n",
    "\\begin{align*}\n",
    "p(\\mathbf{y} | \\boldsymbol \\beta, \\Sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)\\\\\n",
    "= {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}} \\textrm{tr}\\big((\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\big)\\right)\\\\\n",
    "= {}& (2\\pi )^{-n/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}} \\textrm{tr}\\big((\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}\\big)\\right)\\\\\n",
    "p(\\boldsymbol \\Sigma) \\propto 1 \\Longrightarrow {}& \n",
    "\\boldsymbol \\Sigma | \\boldsymbol \\beta, \\mathbf{X},\\mathbf{y} \\sim \\mathcal{W}^{-1}\\left({\\mathbf\\Psi} = (\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top, \\nu = -n \\right)\n",
    "\\end{align*}\n",
    "\n",
    "| |\n",
    "|-|\n",
    "|[an Inverse-Wishart distribution](https://en.wikipedia.org/wiki/Inverse-Wishart_distribution)|\n",
    "\n",
    "\\begin{align*}\n",
    "\\Longrightarrow p(\\boldsymbol \\Sigma ) = {}& {\\frac {\\operatorname{det}({\\mathbf {\\Psi } })^{\\nu /2}}{2^{\\nu n/2}\\Gamma _{n}({\\frac {\\nu }{2}})}}\\operatorname{det}(\\boldsymbol \\Sigma)^{-(\\nu +n+1)/2}e^{-{\\frac {1}{2}}\\operatorname{tr} (\\mathbf {\\Psi } \\boldsymbol \\Sigma ^{-1})}\\hspace{1.66in}\\\\\n",
    "or \\quad {}& \\text{to use a conjugate family of priors...}\\\\\n",
    "p(\\boldsymbol \\Sigma) = {}& \\mathcal{W}^{-1}\\left(\\boldsymbol\\Psi = \\boldsymbol\\Psi_0, \\nu = n+1 \\right) \\quad \\text{ so}\\\\\n",
    "\\boldsymbol \\Sigma | \\boldsymbol \\beta, \\mathbf{X},\\mathbf{y} \\sim {}& \\mathcal{W}^{-1}\\left(\\boldsymbol\\Psi = \\boldsymbol\\Psi_0 + (\\mathbf{y} - \\mathbf{X\\beta})(\\mathbf {y} -\\mathbf{X\\beta})^\\top, \\nu = n+2 \\right)\n",
    "\\end{align*}\n",
    "\n",
    "since [determinants multiply](https://proofwiki.org/wiki/Determinant_of_Matrix_Product) and [traces add](https://proofwiki.org/wiki/Trace_of_Sum_of_Matrices_is_Sum_of_Traces#:~:text=let%20A%2BB%20denote%20the,denotes%20the%20trace%20of%20A.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c1730",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverse-Wishart Distributions [10 minutes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "736401db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of freedom must be greater than the dimension of scale matrix minus 1.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; from scipy import stats\n",
    "p = 2; Psi = np.eye(p) # 2x2 identity\n",
    "try:\n",
    "    stats.invwishart(df=-p, scale=Psi)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40238cb7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So $p(\\boldsymbol \\Sigma) \\propto 1$ is an ***improper prior*** that results in an ***imporoper posterior***\n",
    "\n",
    "If $ p(\\boldsymbol \\Sigma) = \\mathcal{W}^{-1}\\left(\\boldsymbol\\Psi = \\boldsymbol\\Psi_0, \\nu = n+1 \\right  ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9a54e5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47805403, -0.13537446],\n",
       "       [-0.13537446,  0.33091173]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                           # +1 comes from the multivariate normal distribution\n",
    "myIWD = stats.invwishart(df=p+2, scale=Psi); myIWD.rvs(1) # p-1 also won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b85b91",
   "metadata": {},
   "source": [
    "$$E[\\boldsymbol \\Sigma] = \\frac{\\boldsymbol\\Psi}{\\nu - p - 1} \\text{ for } \\boldsymbol \\Sigma \\sim \\mathcal{W}^{-1}(\\boldsymbol \\Psi,\\nu) \\text{ with } \\nu>p+1$$\n",
    "\n",
    "That's why we made the \"interesting\" choice of $\\nu = n+1$ for the ***conjugate prior*** specification above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d135ddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00592141, -0.01463375],\n",
       "       [-0.01463375,  1.03781955]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                       # df=p+1 won't work...\n",
    "myIWD = stats.invwishart(df=p+2, scale=Psi); myIWD.rvs(size=100000).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aac8b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The LKJ (instead of the Inverse-Wishart) Distribution [5 minutes]\n",
    "\n",
    "The ***covariance matrix*** $\\boldsymbol \\Sigma_{p \\times p} = \\mathbf{D R D} = \\mathbf{D LL^\\top D}$ for \n",
    "- $\\mathbf{D} = \\operatorname{diag}(\\boldsymbol \\sigma)$ the ***diagonal matrix*** of ***standard deviations*** \n",
    "- $\\mathbf{R}$ the ***correlation matrix*** with all ***diagonal values*** equal to $1$, and \n",
    "- $\\mathbf{L}$ the ***lower diagonal of the Cholesky decomposition*** of $\\mathbf{R}$\n",
    "\n",
    "<span style='color:white'>\n",
    "\n",
    "The ***LKJ (Lewandowski-Kurowicka-Joe) prior*** is simpler than the ***Inverse-Wishart*** and is [simple to evaluate]\n",
    "\n",
    "$$\\require{cancel} \n",
    "\\begin{align*}\n",
    "p(\\mathbf {R}) \\propto &{}\\det(\\mathbf{R})^{\\eta -1} \\quad f^{-1}(L)=R=LL^\\top \\quad J = \\frac{d f^{-1}(L)}{d L} = \\frac{d LL^\\top}{d L} = \\frac{d R}{d L} \\quad J_{ij} = \\frac{dR_i}{dL_j}\\\\\n",
    "p(\\mathbf {L}) =&{} \\det(\\mathbf{LL^\\top})^{\\eta -1} \\det(J) = \\overbrace{\\left(\\prod_{k=1}^p L_{kk}\\right)^{\\eta -1}}^{\\det(\\mathbf{L})^{\\eta -1}}\\overbrace{\\left(\\prod_{k=1}^p L_{kk}^\\top\\right)^{\\eta -1}}^{\\det(\\mathbf{L^\\top})^{\\eta -1}} \\overbrace{\\left(\\prod_{k=1}^p L_{kk}^{p-k}\\right)}^{\\det(J)} = \\prod_{k=\\cancel{1}2}^p L_{kk}^{p-k + 2(\\eta-1)}\n",
    "\\end{align*}$$\n",
    "\n",
    "and provides efficient computation of $(2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)$ since\n",
    "\n",
    "</span>    \n",
    "    \n",
    "- <font style='color:white'>$\\det({\\boldsymbol {\\Sigma }}) =\\det(\\mathbf{LL^T}) = \\prod_{k=1}^p L_{kk}^2$ (as above) and $(\\mathbf{y}-\\boldsymbol\\mu)^\\top\\boldsymbol\\Sigma^{-1}(\\mathbf{y}-\\boldsymbol\\mu) = \\epsilon^\\top L^{-\\top}L^{-1} \\epsilon = (L^{-1} \\epsilon)^\\top(L^{-1} \\epsilon) = x^\\top x$ where $x$ can be efficiently solved for based on ***lower triangular backwards substitution***  $L\\underset{L^{-1} \\epsilon}{x} = \\epsilon$</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b92138",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The LKJ (instead of the Inverse-Wishart) Distribution [7 minutes]\n",
    "\n",
    "The ***covariance matrix*** $\\boldsymbol \\Sigma_{p \\times p} = \\mathbf{D R D} = \\mathbf{D LL^\\top D}$ for \n",
    "- $\\mathbf{D} = \\operatorname{diag}(\\boldsymbol \\sigma)$ the ***diagonal matrix*** of ***standard deviations*** \n",
    "- $\\mathbf{R}$ the ***correlation matrix*** with all ***diagonal values*** equal to $1$, and \n",
    "- $\\mathbf{L}$ the ***lower diagonal of the Cholesky decomposition*** of $\\mathbf{R}$\n",
    "\n",
    "\n",
    "The ***LKJ (Lewandowski-Kurowicka-Joe) prior*** is simpler than the ***Inverse-Wishart*** and is [simple to evaluate](https://mc-stan.org/docs/functions-reference/cholesky-lkj-correlation-distribution.html) \n",
    "\n",
    "$$\\require{cancel} \n",
    "\\begin{align*}\n",
    "p(\\mathbf {R}) \\propto &{}\\det(\\mathbf{R})^{\\eta -1} \\quad f^{-1}(\\mathbf {L})=\\mathbf {R}=\\mathbf {L}\\mathbf {L}^\\top \\quad J = \\frac{d f^{-1}(\\mathbf {L})}{d \\mathbf {L}} = \\frac{d \\mathbf {L}\\mathbf {L}^\\top}{d \\mathbf {L}} = \\frac{d \\mathbf {R}}{d \\mathbf {L}} \\quad J_{ij} = \\frac{d\\mathbf {r}_i}{d\\mathbf {l}_j}\\\\\n",
    "p(\\mathbf {L}) =&{} \\det(\\mathbf{LL^\\top})^{\\eta -1} \\det(J) = \\overbrace{\\left(\\prod_{k=1}^p \\mathbf {L}_{kk}\\right)^{\\eta -1}}^{\\det(\\mathbf{L})^{\\eta -1}}\\overbrace{\\left(\\prod_{k=1}^p \\mathbf {L}_{kk}^\\top\\right)^{\\eta -1}}^{\\det(\\mathbf{L^\\top})^{\\eta -1}} \\overbrace{\\left(\\prod_{k=1}^p \\mathbf {L}_{kk}^{p-k}\\right)}^{\\det(J)} = \\prod_{k=\\cancel{1}2}^p \\mathbf {L}_{kk}^{p-k + 2(\\eta-1)}\n",
    "\\end{align*}$$\n",
    "\n",
    "<span style='color:white'>\n",
    "\n",
    "and provides efficient computation of $(2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)$ since\n",
    "\n",
    "</span>    \n",
    "    \n",
    "- <font style='color:white'>$\\det({\\boldsymbol {\\Sigma }}) =\\det(\\mathbf{LL^T}) = \\prod_{k=1}^p L_{kk}^2$ (as above) and $(\\mathbf{y}-\\boldsymbol\\mu)^\\top\\boldsymbol\\Sigma^{-1}(\\mathbf{y}-\\boldsymbol\\mu) = \\epsilon^\\top L^{-\\top}L^{-1} \\epsilon = (L^{-1} \\epsilon)^\\top(L^{-1} \\epsilon) = x^\\top x$ where $x$ can be efficiently solved for based on ***lower triangular backwards substitution***  $L\\underset{L^{-1} \\epsilon}{x} = \\epsilon$</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bda6b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The LKJ (instead of the Inverse-Wishart) Distribution [6 minutes]\n",
    "\n",
    "The ***covariance matrix*** $\\boldsymbol \\Sigma_{p \\times p} = \\mathbf{D R D} = \\mathbf{D LL^\\top D}$ for \n",
    "- $\\mathbf{D} = \\operatorname{diag}(\\boldsymbol \\sigma)$ the ***diagonal matrix*** of ***standard deviations*** \n",
    "- $\\mathbf{R}$ the ***correlation matrix*** with all ***diagonal values*** equal to $1$, and \n",
    "- $\\mathbf{L}$ the ***lower diagonal of the Cholesky decomposition*** of $\\mathbf{R}$\n",
    "\n",
    "The ***LKJ (Lewandowski-Kurowicka-Joe) prior*** is simpler than the ***Inverse-Wishart*** and is [simple to evaluate](https://mc-stan.org/docs/functions-reference/cholesky-lkj-correlation-distribution.html) \n",
    "\n",
    "$$\\require{cancel} \n",
    "\\begin{align*}\n",
    "p(\\mathbf {R}) \\propto &{}\\det(\\mathbf{R})^{\\eta -1} \\quad f^{-1}(\\mathbf {L})=\\mathbf {R}=\\mathbf {L}\\mathbf {L}^\\top \\quad J = \\frac{d f^{-1}(\\mathbf {L})}{d \\mathbf {L}} = \\frac{d \\mathbf {L}\\mathbf {L}^\\top}{d \\mathbf {L}} = \\frac{d \\mathbf {R}}{d \\mathbf {L}} \\quad J_{ij} = \\frac{d\\mathbf {r}_i}{d\\mathbf {l}_j}\\\\\n",
    "p(\\mathbf {L}) =&{} \\det(\\mathbf{LL^\\top})^{\\eta -1} \\det(J) = \\overbrace{\\left(\\prod_{k=1}^p \\mathbf {L}_{kk}\\right)^{\\eta -1}}^{\\det(\\mathbf{L})^{\\eta -1}}\\overbrace{\\left(\\prod_{k=1}^p \\mathbf {L}_{kk}^\\top\\right)^{\\eta -1}}^{\\det(\\mathbf{L^\\top})^{\\eta -1}} \\overbrace{\\left(\\prod_{k=1}^p \\mathbf {L}_{kk}^{p-k}\\right)}^{\\det(J)} = \\prod_{k=\\cancel{1}2}^p \\mathbf {L}_{kk}^{p-k + 2(\\eta-1)}\n",
    "\\end{align*}$$\n",
    "\n",
    "and provides efficient computation of $(2\\pi )^{-k/2}\\det({\\boldsymbol {\\Sigma }})^{-1/2}\\,\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\beta})^\\top{\\boldsymbol {\\Sigma }}^{-1}(\\mathbf{y} - \\mathbf{X\\beta})\\right)$ since\n",
    "\n",
    "- $\\det({\\boldsymbol {\\Sigma }}) =\\det(\\mathbf{LL^T}) = \\prod_{k=1}^p \\mathbf {L}_{kk}^2$ (as above) and $(\\mathbf{y}-\\boldsymbol\\mu)^\\top\\boldsymbol\\Sigma^{-1}(\\mathbf{y}-\\boldsymbol\\mu) = \\boldsymbol \\epsilon^\\top \\mathbf {L}^{-\\top}\\mathbf {L}^{-1} \\boldsymbol \\epsilon = (\\mathbf {L}^{-1} \\boldsymbol \\epsilon)^\\top(\\mathbf {L}^{-1} \\boldsymbol \\epsilon) = \\mathbf {x}^\\top \\mathbf {x}$ where $\\mathbf {x}$ can be efficiently solved for based on ***lower triangular backwards substitution***  $\\mathbf {L}\\underset{\\mathbf {L}^{-1} \\boldsymbol \\epsilon}{x} = \\boldsymbol \\epsilon$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a1e49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The LKJ (instead of the Inverse-Wishart) Distribution [4 minutes]\n",
    "\n",
    "\n",
    "$p(\\boldsymbol \\Sigma) = p(\\boldsymbol \\sigma)p(\\mathbf {R})$ and the $\\eta=1$ \n",
    "***hyperparameter*** specifies a uniform distribution on ***correlation matrices***\n",
    "\n",
    "$$p(\\mathbf {R}) \\propto \\det(\\mathbf{R}_{p \\times p})^{\\eta -1} \\quad \\text{ $\\eta=1$ gives proper posteriors since } p(\\mathbf {R}) \\propto 1 \\text{ is not the same as }p(\\boldsymbol \\Sigma)\\propto 1 $$\n",
    "\n",
    "- <font style='color:white'>The absolute ***determinant*** is the product of the ***singular values***<br>(and the ***determinant*** is positive for ***positive definite matrices***)</font>\n",
    "- <font style='color:white'>For ***correlation matrices*** the ***determinant*** is largest when all ***singular values*** (which sum to $p$)<br>\n",
    "are equal to $1$ which happens when all off-diagonal correlations are $0$</font>\n",
    "\n",
    "<font style='color:white'>Increasing $\\eta \\rightarrow \\infty$ thus favors ***correlation matrices*** with \n",
    "smaller magnitudes of component correlations</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16053284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564264ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The LKJ (instead of the Inverse-Wishart) Distribution [4 minutes]\n",
    "\n",
    "\n",
    "$p(\\boldsymbol \\Sigma) = p(\\boldsymbol \\sigma)p(\\mathbf {R})$ and the $\\eta=1$ \n",
    "***hyperparameter*** specifies a uniform distribution on ***correlation matrices***\n",
    "\n",
    "$$p(\\mathbf {R}) \\propto \\det(\\mathbf{R}_{p \\times p})^{\\eta -1} \\quad \\text{ $\\eta=1$ gives proper posteriors since } p(\\mathbf {R}) \\propto 1 \\text{ is not the same as }p(\\boldsymbol \\Sigma)\\propto 1 $$\n",
    "\n",
    "- The absolute ***determinant*** is the product of the ***singular values***<br>(and the ***determinant*** is positive for ***positive definite matrices***)\n",
    "- For ***correlation matrices*** the ***determinant*** is largest when all ***singular values*** (which sum to $p$)<br>\n",
    "are equal to $1$ which happens when all off-diagonal correlations are $0$\n",
    "\n",
    "Increasing $\\eta \\rightarrow \\infty$ thus favors ***correlation matrices*** with \n",
    "smaller magnitudes of component correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03958e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e7286",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The LKJ (instead of the Inverse-Wishart) Distribution [4 minutes]\n",
    "\n",
    "\n",
    "$p(\\boldsymbol \\Sigma) = p(\\boldsymbol \\sigma)p(\\mathbf {R})$ and the $\\eta=1$ \n",
    "***hyperparameter*** specifies a uniform distribution on ***correlation matrices***\n",
    "\n",
    "$$p(\\mathbf {R}) \\propto \\det(\\mathbf{R}_{p \\times p})^{\\eta -1} \\quad \\text{ $\\eta=1$ gives proper posteriors since } p(\\mathbf {R}) \\propto 1 \\text{ is not the same as }p(\\boldsymbol \\Sigma)\\propto 1 $$\n",
    "\n",
    "- The absolute ***determinant*** is the product of the ***singular values***<br>(and the ***determinant*** is positive for ***positive definite matrices***)\n",
    "- For ***correlation matrices*** the ***determinant*** is largest when all ***singular values*** (which sum to $p$)<br>\n",
    "are equal to $1$ which happens when all off-diagonal correlations are $0$\n",
    "\n",
    "Increasing $\\eta \\rightarrow \\infty$ thus favors ***correlation matrices*** with \n",
    "smaller magnitudes of component correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "338ddfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15250025, -0.15400333,  1.12802046])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymc as pm # https://www.pymc.io/projects/examples/en/latest/case_studies/LKJ.html\n",
    "# https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.LKJCholeskyCov.html\n",
    "with pm.Model() as LKJ:\n",
    "    packed_L = pm.LKJCholeskyCov(\"packed_L\", n=2, eta=2.0, \n",
    "                                 sd_dist=pm.Exponential.dist(1.0, shape=2), compute_corr=False)\n",
    "packed_L.eval()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1f0e4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02325633, -0.02348555],\n",
       "       [-0.02348555,  1.29614719]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with LKJ:\n",
    "    L = pm.expand_packed_triangular(2, packed_L)\n",
    "    Sigma = L.dot(L.T)\n",
    "Sigma.eval()#.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e91d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Multivariate Normal Inference: the MVN-LKJ model<br>*as opposed to Bayesian Linear Regression* [5 minutes]\n",
    "\n",
    "$$\\scriptsize\n",
    "\\begin{align*}\\require{cancel}\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}\\cancel{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}{\\frac{1}{\\sigma^{\\frac{n}{2}}}}\\exp \\left(-{\\frac {1}{2\\sigma^2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top\\cancel{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\\hline\\\\\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} \\cancel{= \\sigma^2I_{n\\times n}})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\\hline\\\\\n",
    "\\mathbf{y}_{i} \\sim {} & \\mathcal{MVN}(\\boldsymbol \\mu,\\boldsymbol \\Sigma = \\mathbf{DRD})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-p/2}{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} - \\boldsymbol\\mu)^\\top{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\boldsymbol\\mu)\\right)\\\\\n",
    "\\boldsymbol\\beta \\sim {} & \\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta) \\quad\\quad\n",
    "\\mathbf {R} \\sim \\mathcal{LKJ}(\\eta) \\quad\\quad p(\\mathbf {R}) \\propto \\det(\\mathbf{R})^{\\eta -1} \\quad\\quad p(\\mathbf {L}) = \\prod_{k=\\cancel{1}2}^p \\mathbf {L}_{kk}^{p-k + 2(\\eta-1)}\n",
    " \\\\\n",
    "\\sigma_i \\sim {} & exponential(\\lambda)\\quad \\text{ and } \\quad \\mathbf{D}=\\text{diag}(\\boldsymbol \\sigma)  \\quad\\quad\\quad p(\\sigma_i) =  \\lambda e^{-\\lambda \\sigma_i}1_{[0,\\infty]}(\\sigma_i)\n",
    "\\end{align*}$$\n",
    "\n",
    "$$\\color{white}{(2\\pi )^{-p/2}{\\overset{\\prod_{i=1}^nD_{ii}^2L_{ii}^2}{\\det({\\mathbf {DLL^\\top D }}})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} - \\boldsymbol\\mu)^\\top{ \\overset{\\mathbf {D^{-1}L^{-\\top} L^{-1} D^{-1}} } {(\\mathbf {DLL^\\top D })^{-1}}}(\\mathbf {y} - \\boldsymbol\\mu)\\right) \\overset{  \\prod_{k=\\cancel{1}2}^p \\mathbf {L}_{kk}^{p-k + 2(\\eta-1)}}{\\times \\underset{p(\\mathbf{R})}{\\det(\\mathbf{R})^{\\eta -1}} \\times}  \\prod_{i=1}^p \\lambda e^{-\\lambda \\sigma_i}1_{[0,\\infty]}(\\sigma_i)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c762d693",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Multivariate Normal Inference: the MVN-LKJ model<br>*as opposed to Bayesian Linear Regression* [3 minutes]\n",
    "\n",
    "$$\\scriptsize\n",
    "\\begin{align*}\\require{cancel}\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} = \\sigma^2I_{n\\times n})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}\\cancel{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}{\\frac{1}{\\sigma^{\\frac{n}{2}}}}\\exp \\left(-{\\frac {1}{2\\sigma^2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top\\cancel{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\\hline\\\\\n",
    "\\mathbf{y}_{n\\times 1} \\sim {} & \\mathcal{MVN}(\\mathbf{X}_{n\\times p}\\boldsymbol{\\beta}_{p\\times 1},\\boldsymbol \\Sigma_{n\\times n} \\cancel{= \\sigma^2I_{n\\times n}})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-n/2}{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} -\\mathbf{X\\boldsymbol\\beta})^\\top{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\mathbf{X\\boldsymbol\\beta})\\right)\\\\\\\\\\hline\\\\\n",
    "\\mathbf{y}_{i} \\sim {} & \\mathcal{MVN}(\\boldsymbol \\mu,\\boldsymbol \\Sigma = \\mathbf{DRD})\\\\\n",
    "p(\\mathbf{y}|\\boldsymbol \\beta, \\sigma, \\mathbf{X}) = {}& (2\\pi )^{-p/2}{\\det({\\boldsymbol {\\Sigma }})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} - \\boldsymbol\\mu)^\\top{\\boldsymbol {\\Sigma }^{-1}}(\\mathbf {y} - \\boldsymbol\\mu)\\right)\\\\\n",
    "\\boldsymbol\\beta \\sim {} & \\mathcal{MVN}(\\boldsymbol\\beta_0, \\boldsymbol\\Sigma_\\beta) \\quad\\quad\n",
    "\\mathbf {R} \\sim \\mathcal{LKJ}(\\eta) \\quad\\quad p(\\mathbf {R}) \\propto \\det(\\mathbf{R})^{\\eta -1} \\quad\\quad p(\\mathbf {L}) = \\prod_{k=\\cancel{1}2}^p \\mathbf {L}_{kk}^{p-k + 2(\\eta-1)}\n",
    " \\\\\n",
    "\\sigma_i \\sim {} & exponential(\\lambda)\\quad \\text{ and } \\quad \\mathbf{D}=\\text{diag}(\\boldsymbol \\sigma)  \\quad\\quad\\quad p(\\sigma_i) =  \\lambda e^{-\\lambda \\sigma_i}1_{[0,\\infty]}(\\sigma_i)\n",
    "\\end{align*}$$\n",
    "\n",
    "$$\\color{gray}{(2\\pi )^{-p/2}{\\overset{\\prod_{i=1}^nD_{ii}^2L_{ii}^2}{\\det({\\mathbf {DLL^\\top D }}})^{-1/2}}\\exp \\left(-{\\frac {1}{2}}(\\mathbf {y} - \\boldsymbol\\mu)^\\top{ \\overset{\\mathbf {D^{-1}L^{-\\top} L^{-1} D^{-1}} } {(\\mathbf {DLL^\\top D })^{-1}}}(\\mathbf {y} - \\boldsymbol\\mu)\\right) \\overset{  \\prod_{k=\\cancel{1}2}^p \\mathbf {L}_{kk}^{p-k + 2(\\eta-1)}}{\\times \\underset{p(\\mathbf{R})}{\\det(\\mathbf{R})^{\\eta -1}} \\times}  \\prod_{i=1}^p \\lambda e^{-\\lambda \\sigma_i}1_{[0,\\infty]}(\\sigma_i)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449185a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Multivariate Normal Inference: the MVN-LKJ model<br>*as opposed to Bayesian Linear Regression* [12 minutes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ab29ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [packed_L, mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 20:50&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1251 seconds.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; from scipy import stats; import pymc as pm; p=25; Psi=np.eye(p); a_cov = stats.invwishart(df=10*p+2, scale=Psi).rvs()\n",
    "n=500; y=stats.multivariate_normal(mean=np.zeros(p), cov=a_cov).rvs(size=n)\n",
    "with pm.Model() as MNV_LKJ:\n",
    "    packed_L = pm.LKJCholeskyCov(\"packed_L\", n=p, eta=2.0, sd_dist=pm.Exponential.dist(1.0, shape=2), compute_corr=False)\n",
    "    L = pm.expand_packed_triangular(p, packed_L); Sigma = pm.Deterministic('Sigma', L.dot(L.T))\n",
    "    mu = pm.MvNormal('mu', mu=np.array(0), cov=np.eye(p), shape=p); \n",
    "    lik = pm.MvNormal('lik', mu=mu, cov=Sigma, shape=(n,1), observed=y)\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92195e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as MNV_LKJ:\n",
    "    packed_L = pm. LKJCholeskyCov(\"packed_L\", n=p, eta=2.0,\n",
    "    sd_dist=pm.Gamma.dist (alpha = 2, beta = 2), compute_corr=False)\n",
    "    L = pm. expand_packed_triangular (p, packed_L);\n",
    "    Sigma = pm.Deterministic( 'Sigma', L.dot (L.T))\n",
    "    mu = pm.Normal('mu', mu=1, sigma = 1);\n",
    "    lik = pm.MvNormal('lik', mu=mu, cov=Sigma, observed=y)\n",
    "    idata = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7544fd54",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sd/hnfh4zsn34d7xpbz9226pz200000gn/T/ipykernel_81592/3882271250.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_cov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sigma used to generate y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sigma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chian\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mean Sigma\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/PyMC/lib/python3.11/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;31m# xarray-style array indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_key_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PyMC/lib/python3.11/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36misel\u001b[0;34m(self, indexers, drop, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0;31m# lists, or zero or one-dimensional np.ndarray's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m         \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissing_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1454\u001b[0m         \u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misel_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PyMC/lib/python3.11/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36misel\u001b[0;34m(self, indexers, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PyMC/lib/python3.11/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \"\"\"\n\u001b[1;32m    891\u001b[0m         \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PyMC/lib/python3.11/site-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indexing_array_and_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt; fig,ax = plt.subplots(1,5,figsize=(18,4)); ax[-1].imshow(a_cov); ax[0].set_title((\"Sigma used to generate y\"))\n",
    "for chain in range(4):\n",
    "    ax[chain].imshow(idata.posterior['Sigma'].mean(axis=1)[chain+1]); ax[chain].set_title((\"chian\",chain,\"mean Sigma\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad2ed1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework 5: Part III\n",
    "\n",
    "1. Go get data from kaggle.com and perform inference for a ***Bayesian Multivariate Normal Model***\n",
    "\n",
    "<SPAN STYLE=\"font-size:18.0pt\">\n",
    "\n",
    "```python\n",
    "import numpy as np; from scipy import stats\n",
    "p=10; Psi=np.eye(p); a_cov = stats.invwishart(df=p+2, scale=Psi).rvs(1)\n",
    "n=1000; y=stats.multivariate_normal(mean=np.zeros(p), cov=a_cov).rvs(size=n)\n",
    "# Replace this made up data with your data set from kaggle...\n",
    "    \n",
    "with pm.Model() as MNV_LKJ:\n",
    "    packed_L = pm.LKJCholeskyCov(\"packed_L\", n=p, eta=2.0,\n",
    "                                 sd_dist=pm.Exponential.dist(1.0, shape=2), compute_corr=False)\n",
    "    L = pm.expand_packed_triangular(p, packed_L)\n",
    "    # Sigma = pm.Deterministic('Sigma', L.dot(L.T)) # Don't use a covariance matrix parameterization\n",
    "    mu = pm.MvNormal('mu', mu=np.array(0), cov=np.eye(p), shape=p); \n",
    "    # y = pm.MvNormal('y', mu=mu, cov=Sigma, shape=(n,1), observed=y) \n",
    "    # Figure out how to parameterize this with a Cholesky factor to improve computational efficiency \n",
    "with MNV_LKJ    \n",
    "    idata = pm.sample()\n",
    "```    \n",
    "</SPAN>\n",
    "\n",
    "2. As indicated above, don't use a covariance matrix parameterization and instead figure out how to parameterize this with a ***Cholesky factor*** to improve computational efficiency. The ***Cholesky***-based formulation allows general $O(n^3)$ $\\det({\\boldsymbol \\Sigma})$ to be computed using a simple $O(n)$ product and general $O(n^3)$ ${\\boldsymbol \\Sigma}^{-1}$ to be instead evaluated with $O(n^2)$ ***backward substitution***. \n",
    "\n",
    "2. Specify ***priors*** that work: certainly you'll likely need to change the ***prior hyperparameters*** for $\\boldsymbol \\mu$ (`mu`) and $\\mathbf{R}$ (`packed_L`)...\n",
    "    1. And you could consider adjusting the ***prior*** for $\\boldsymbol \\sigma$ using `sd_dist`... \n",
    "\n",
    "3. [Optional] Assess the performance of the MCMC and note any issues\n",
    "\n",
    "    1. Traceplots, inference (credible) intervals, effective sample sizes, energy plots, warnings and other notes... just the usual stuff they do [here](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/pymc_overview.html#pymc-overview)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
